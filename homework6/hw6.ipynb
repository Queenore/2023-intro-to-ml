{
  "metadata" : {
    "config" : {
      "dependencies" : {
        
      },
      "exclusions" : [
      ],
      "repositories" : [
      ],
      "sparkConfig" : {
        "spark.master" : "local[1]"
      },
      "env" : {
        
      }
    },
    "language_info" : {
      "name" : "scala"
    }
  },
  "nbformat" : 4,
  "nbformat_minor" : 0,
  "cells" : [
    {
      "cell_type" : "markdown",
      "execution_count" : 0,
      "metadata" : {
        "language" : "text"
      },
      "language" : "text",
      "source" : [
        "# hw 6\n",
        "\n",
        "\n",
        "<div>Студент Чешев А. Д.</div>\n"
      ],
      "outputs" : [
      ]
    },
    {
      "cell_type" : "code",
      "execution_count" : 2,
      "metadata" : {
        "cell.metadata.exec_info" : {
          "startTs" : 1703525447836,
          "endTs" : 1703525452553
        },
        "language" : "scala"
      },
      "language" : "scala",
      "source" : [
        "// 1.\r\n",
        "\r\n",
        "val sc = spark.sparkContext\r\n",
        "val imdbSpark = SparkSession.builder().appName(\"IMDB\").config(sc.getConf).getOrCreate()\r\n",
        "\r\n",
        "val filePathTest = \"datasets/IMDBSentimentAnalysis/Test.csv\"\r\n",
        "val filePathTrain = \"datasets/IMDBSentimentAnalysis/Train.csv\"\r\n",
        "val filePathValid = \"datasets/IMDBSentimentAnalysis/Valid.csv\"\r\n",
        "\r\n",
        "val imdbTrainDataset: DataFrame = imdbSpark.read.option(\"header\", \"true\").csv(filePathTrain)\r\n",
        "val imdbTestDataset: DataFrame = imdbSpark.read.option(\"header\", \"true\").csv(filePathTest)\r\n",
        "val imdbValidDataset: DataFrame = imdbSpark.read.option(\"header\", \"true\").csv(filePathValid)"
      ],
      "outputs" : [
      ]
    },
    {
      "cell_type" : "code",
      "execution_count" : 8,
      "metadata" : {
        "cell.metadata.exec_info" : {
          "startTs" : 1703525628630,
          "endTs" : 1703525628740
        },
        "language" : "scala"
      },
      "language" : "scala",
      "source" : [
        "import org.apache.spark.sql.DataFrame\r\n",
        "import org.apache.spark.sql.functions.col\r\n",
        "\r\n",
        "// Метод, который оставляет только значения \"0\" и \"1\" в колонке label.\r\n",
        "def filterLabels(df: DataFrame): DataFrame = {\r\n",
        "  df.withColumn(\"label\", col(\"label\").cast(\"int\")).filter(\"label == 0 OR label == 1\")\r\n",
        "}\r\n",
        "\r\n",
        "// Получаем отфильтрованные датасеты.\r\n",
        "val imdbTrainFiltered = filterLabels(imdbTrainDataset)\r\n",
        "val imdbTestFiltered = filterLabels(imdbTestDataset)\r\n",
        "val imdbValidFiltered = filterLabels(imdbValidDataset)"
      ],
      "outputs" : [
      ]
    },
    {
      "cell_type" : "code",
      "execution_count" : 4,
      "metadata" : {
        "cell.metadata.exec_info" : {
          "startTs" : 1703525716040,
          "endTs" : 1703525723172
        },
        "language" : "scala"
      },
      "language" : "scala",
      "source" : [
        "import org.apache.spark.ml.linalg.Vector\r\n",
        "import org.apache.spark.ml.classification.LogisticRegression\r\n",
        "import org.apache.spark.ml.{Pipeline, PipelineModel}\r\n",
        "import org.apache.spark.ml.feature.{HashingTF, Tokenizer}\r\n",
        "import org.apache.spark.sql.functions._\r\n",
        "import org.apache.spark.sql.{DataFrame, SparkSession}\r\n",
        "\r\n",
        "// Создание экземпляра Tokenizer для разделения текста на токены.\r\n",
        "val tokenizer = new Tokenizer().setInputCol(\"text\").setOutputCol(\"words\")\r\n",
        "// Создание экземпляра HashingTF для преобразования токенов в вектор признаков с использованием хэширования.\r\n",
        "// В данном случае эмпирическим путем выбрано наиболее оптимальное значение параметара NumFeatures = 11500.\r\n",
        "val hashingTF = new HashingTF().setInputCol(\"words\").setOutputCol(\"features\").setNumFeatures(11500)\r\n",
        "// Создание экземпляра LogisticRegression с установкой параметров обучения.\r\n",
        "val lr = new LogisticRegression().setMaxIter(10).setRegParam(0.01)\r\n",
        "// Создание конвейера (pipeline), включающего в себя последовательное применение Tokenizer, HashingTF и LogisticRegression.\r\n",
        "val pipeline = new Pipeline().setStages(Array(tokenizer, hashingTF, lr))\r\n",
        "\r\n",
        "// Обучим модель.\r\n",
        "val model = pipeline.fit(imdbTrainFiltered)\r\n",
        "\r\n",
        "// Протестируем на тестовой выборке.\r\n",
        "val predictions = model.transform(imdbTestFiltered)\r\n",
        "// Выведем полученные предсказания для визуального сравнения результатов.\r\n",
        "predictions.select(\"text\", \"label\", \"prediction\").show()\r\n",
        "\r\n",
        "model.write.overwrite().save(\"imdb_model\")"
      ],
      "outputs" : [
        {
          "name" : "stdout",
          "text" : [
            "+--------------------+-----+----------+\n",
            "|                text|label|prediction|\n",
            "+--------------------+-----+----------+\n",
            "|1st watched 12/7/...|    0|       0.0|\n",
            "|I saw a screening...|    0|       1.0|\n",
            "|William Hurt may ...|    1|       1.0|\n",
            "|IT IS A PIECE OF ...|    0|       0.0|\n",
            "|I'M BOUT IT(1997)...|    0|       0.0|\n",
            "|I really enjoyed ...|    1|       0.0|\n",
            "|This movie was re...|    0|       0.0|\n",
            "|I felt asleep, wa...|    0|       0.0|\n",
            "|Brass pictures (m...|    0|       1.0|\n",
            "|My interest was r...|    1|       1.0|\n",
            "|Love Jones clever...|    1|       1.0|\n",
            "|This is a funny f...|    1|       1.0|\n",
            "|Like several othe...|    1|       1.0|\n",
            "|Film version of S...|    0|       0.0|\n",
            "|Spoken like a tru...|    0|       0.0|\n",
            "|I think it was an...|    0|       0.0|\n",
            "|This movie is goo...|    1|       1.0|\n",
            "|I vaguely remembe...|    0|       0.0|\n",
            "|One of the finest...|    1|       1.0|\n",
            "|We watched this i...|    1|       1.0|\n",
            "+--------------------+-----+----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "output_type" : "stream"
        }
      ]
    },
    {
      "cell_type" : "code",
      "execution_count" : 6,
      "metadata" : {
        "cell.metadata.exec_info" : {
          "startTs" : 1703525725824,
          "endTs" : 1703525727430
        },
        "language" : "scala"
      },
      "language" : "scala",
      "source" : [
        "// 2.\r\n",
        "\r\n",
        "// Загрузим ранее созданную модель.\r\n",
        "val loadedModel = PipelineModel.load(\"imdb_model\")\r\n",
        "\r\n",
        "// Предсказания на valid датасете.\r\n",
        "val predictionsOnValidDataset = loadedModel.transform(imdbValidFiltered)\r\n",
        "predictionsOnValidDataset.select(\"text\", \"label\", \"prediction\").show()"
      ],
      "outputs" : [
        {
          "name" : "stdout",
          "text" : [
            "+--------------------+-----+----------+\n",
            "|                text|label|prediction|\n",
            "+--------------------+-----+----------+\n",
            "|someone needed to...|    0|       0.0|\n",
            "|The Guidelines st...|    0|       0.0|\n",
            "|This movie is a m...|    0|       0.0|\n",
            "|Before Stan Laure...|    0|       1.0|\n",
            "|This is the best ...|    1|       1.0|\n",
            "|Somebody mastered...|    1|       1.0|\n",
            "|Why did I waste 1...|    0|       0.0|\n",
            "|This film takes y...|    1|       1.0|\n",
            "|The Russian space...|    0|       0.0|\n",
            "|I had seen 'Kalif...|    1|       1.0|\n",
            "|I really enjoyed ...|    0|       1.0|\n",
            "|Hi, Everyone, Oh,...|    0|       0.0|\n",
            "|It takes a while ...|    1|       1.0|\n",
            "|If you're one of ...|    0|       1.0|\n",
            "|This is better th...|    0|       0.0|\n",
            "|The first time I ...|    0|       1.0|\n",
            "|One of the great ...|    1|       1.0|\n",
            "|An excellent fami...|    1|       1.0|\n",
            "|The next-to-last ...|    1|       1.0|\n",
            "|Today You Die was...|    0|       0.0|\n",
            "+--------------------+-----+----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "output_type" : "stream"
        }
      ]
    },
    {
      "cell_type" : "code",
      "execution_count" : 7,
      "metadata" : {
        "cell.metadata.exec_info" : {
          "startTs" : 1703525727888,
          "endTs" : 1703525729486
        },
        "language" : "scala"
      },
      "language" : "scala",
      "source" : [
        "import org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator\r\n",
        "\r\n",
        "// Создание экземпляра оценщика для многоклассовой классификации.\r\n",
        "// Устанавливаются параметры:\r\n",
        "//  - столбец с истинными метками (\"label\");\r\n",
        "//  - столбец с предсказанными метками (\"prediction\").\r\n",
        "// Выбирается метрика:\r\n",
        "//  - метрика оценки качества - точность (\"accuracy\").\r\n",
        "val evaluator = new MulticlassClassificationEvaluator()\r\n",
        "  .setLabelCol(\"label\")\r\n",
        "  .setPredictionCol(\"prediction\")\r\n",
        "  .setMetricName(\"accuracy\")\r\n",
        "\r\n",
        "// Вычислим характеристику accuracy.\r\n",
        "val accuracy = evaluator.evaluate(predictionsOnValidDataset)\r\n",
        "println(s\"Accuracy: ${accuracy * 100}\")"
      ],
      "outputs" : [
        {
          "name" : "stdout",
          "text" : [
            "Accuracy: 84.31506849315068\n"
          ],
          "output_type" : "stream"
        }
      ]
    }
  ]
}